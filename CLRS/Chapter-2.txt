RAM model
is basically a simplified yet perfect, idealized pc
because algorithm speed is hard to measure we need a standard unit, thus the ram model is used

Time depends on input size & shape

Measuring input size
array = n
numbers = number of bits to represetn them
graphs= vertices, edges
pick a measure that makes sense


running time = how long your algorithm takes from start to finish
sum of (cost of operation x number of time it executes) 
sometimes it depends on the size of the input
and how already "sorted" the input is

Exercises
2.2-1
Express the function n^3/1000 - 100n^2 + 3 in terms of the O notation.

worst case = n^3. we can ignore the n^2 or constant
its a cubic function with power of 3

as the input grows larger, n^3 is the most dominant change

big O notation = On(n^3)

===========================================================

Exercise 2.2-1
Consider sorting n numbers stored in array A by first finding the smallest element
of A and exchanging it with the element in A[1]. Then find the second smallest
element of A, and exchange it with A[2]. Continue in this manner for the first n 1
elements of A. Write pseudocode for this algorithm, which is known as selection
sort. What loop invariant does this algorithm maintain? Why does it need to run
for only the first n 1 elements, rather than for all n elements? Give the best-case
and worst-case running times of selection sort in big O notation.

answer:
selection sort
first, find smallest element of A -> exchange with A[1]
second, find second smallest element of A -> exchange it with A[2]
continue until n-1 input

loop invariant: what needs to be true before, during and at the end?
the subarray a[1,...i-1] is sorted and contains i-1 smallest element of the original array. the remaining subarray is unsorted

initialization: before selection sort starts, the sorted array is empty, trivially contains 0 smallest element
Maintenance: if the first i-1 position contain i-1 smallest elment, then after swapping next smallest into a[i], now the first i position contain smallest i element
Termination: when i = n, the first n-1 position holds the smallest n-1 elements in sorted order. the last element is already sorted.


why it needs to rn only for the first n-1 element?
let see, first we need to find smallest element of the input
if the input is {1,9,4,5}
first we pick 1, put it into the first position
then 4, put it at 2nd,
then 5, put it in 3rd
finally 9 at the end - the 9 is already sorted by now
this is why we only need n-1

pseudocode:
let arr = [arr inputs]
let n = arr.length
let i = 1
while(i < n)
    let j = i+1
    let minIndex = i
    while(j < n)
        if arr[j] < arr[minIndex]
            minIndex = j
        j = j + 1
    end while
    swap arr[i] with arr[minIndex]
    i = i + 1
end while
    
Best case: the list is already sorted


while(i < n)
outer loop: runs n-1 times

while(j < n)
inner loop: runs n times


outer loop still iterates through n-1 times
inner loop still copmares all remainig elements ot find the minimum
big O notation: O(n^2)

Worst case: the list is sorted in reverse
outer loop still tierates through n-1 times
inner looop also still runs
big O notation: O(n^2)

Exercise 2.2-3
Consider linear search again (see Exercise 2.1-3). How many elements of the in
put sequence need to be checked on the average, assuming that the element being
searched for is equally likely to be any element in the array? How about in the
worst case? What are the average-case and worst-case running times of linear
search in big O notation? Justify your answers.

answer:
from exercise 2.1-3
let i = 1
 while i <= n
     if a[i] = v
        return i,
        i = i + 1
return nil

how many elements of the input seq needs to be checked on average?
if the input length is n then we need to check all of them until the item is found

best case item is at the start of the array, check 1 times => O(1)
worst case item is at the end of the array  => O(n)
average case item is in the middle of the array,  check 1+2+3+...+n/n times times => O(n)


2.2-4
How can we modify almost any algorithm to have a good best-case running time?
answer: by performing less computation
by adding a preliminary check at the begininng of the algorithm
the check should test if the input satisfies a condition that allows for a trivially fast answer

for sorting algorithm, best case input if it's already sorted, so add that check
for searching, check if arr[0] already contains the thing you're looking for

===========================================================

2.3
divide an conquer approach
1. divide problem into a number of subproblem, smlaler instances of the same problem

Merge sort example:
divide: divide n-element sequence to be sorted into two subsequences of n/2
conquer: sort the two subsequences recursively using merge sort
combine: merge the two sorted subsequence to produce the sorted answer

base case: trivally length is 1 (already sorted)


Loop invariant:
The portion of A we’ve filled so far already has the smallest elements in sorted order.
L[i] and R[j] are the next candidates to be placed.

===========================================================

Recurrence Relation
T(1) = c
T(n) = 2T(n/2) + cn for n > 1

Exercise 2.3-1
Using figure 2.4 as a model, illustrate the operation of merge sort on the array
A = {3,41,52,9}
initial sequence = {3,41,52, 26, 38, 57, 9, 49}
divide  -> {3,41,52, 26}, {38, 57, 9, 49}
{3,41} {52,26} {38,57} {9,49}
{3} {41} {52} {26} {38} {57} {9} {49}
conquer & merge -> {3,41} {26, 52}, {38, 57}, {9, 49}
{3, 26, 41, 52} {9,38,49,57}
{3, 9, 26, 38, 41, 49, 52, 57}

2.3-2
Rewrite the MERGE procedure so that it does not use sentinels, instead stopping
once either array L or R has had all its elements copied back to A and then copying
the remainder of the other array back into A.

Original pseudocode with sentinel:

where A= arr, p = 1st index, q = mid index, r = last index of the array
left half = A[p...q]
right half = A[q+1...r]

MERGE(A,p,q,r)
n1 = q - p + 1 ; length of left half
n2 = r - q  ;length of right half
let L[1...n1+1] and R[1...n2+1] be new arrys ;temporary array

for i = 1 to n1 ;loop from 1 to length of the left half + sentinel
    L[i] = A[p + i - 1] ; copy the content
for j = 1 to n2 ; loop from 1 to length of the right half + sentinel
    R[j] = A[q + j] ;copy the content
L[n1 + 1] = ∞ ;replace last item in left array with sentinel
R[n2 + 1] = ∞ ;replace last item in right array with sentinel

i = 1 ;index for left array, initialize to 1
j = 1 ;index for right arary, initialize to 1

for k = p to r ; loop from p to r (loop through the length of the original array)
    if L[i] <= R[j] ; compare curr item of L & R array at curr index, if left item is less than or equal to right item 
        A[k] = L[i] ; mutate the original array - replace its ocntent with left item
        i = i + 1 ; increase counter of the left array
    else A[k] = R[j] ; otherwise mutate original array's content with right item
        j = j + 1 ; increase counter of the right array


==================================================

Pseudocode without sentinel:

where A= arr, p = 1st index, q = mid index, r = last index of the array
left half = A[p...q]
right half = A[q+1...r]

MERGE(A,p,q,r)
n1 = q - p + 1 ; length of left half
n2 = r - q  ;length of right half
let L[1...n1] and R[1...n2] be new arrys ;temporary array

for i = 1 to n1 ;loop from 1 to length of the left half
    L[i] = A[p + i - 1] ; copy the content
for j = 1 to n2 ; loop from 1 to length of the right half
    R[j] = A[q + j] ;copy the content

k = p ;pointer for original array, start at p
i = 1 ;index for left array, initialize to 1
j = 1 ;index for right arary, initialize to 1

while i <= n1 and j <= n2 (loop while left & right arr is not empty)
    if L[i] <= R[j] ; pick smaller, advance index
        A[k] = L[i]
        i = i + 1
    else
        A[k] = R[j]
        j = j + 1
    k = k + 1

while i <= n1
    A[k] = L[i]
    i = i + 1
    k = k + 1

while j <= n2
    A[k] = R[j]
    j = j + 1
    k = k + 1

MERGE-SORT(A,p,r)
if p < r
    q = floor((p + r) / 2)
    MERGE-SORT(A,p,q)
    MERGE-SORT(A,q+1,r)
    MERGE(A,p,q,r)
    
    
2.3-3
Use mathemtical induction to show that when n is an exact power of 2,
the solution of the recurrence

T(n) = {
    2               if n = 2
    2t(n/2) + n     if n = 2^k, for k > 1    
}

is T(n) = n log n

base case: 
check if formula works for base case
T(2) = 2 . lg 2 = 1

inductive hypothesis
assume the formla works for an abitrary input, lets say n/2
T(n/2) = n/2 lg n/2
= n/2 . lg n - lg 2
= n/2 (lg n - 1)


inductive step: show that if it works for n/2, then it works for n
substitute this into the recurrence
t(n) = 2 t(n/2) + n 
= 2 (n/2 (lg n - 1)) + n
= n (lg n - 1) + n
= n lg n - n + n
= n lg n


2.3-4
 We can express insertion sort as a recursive procedure as follows. In order to sort
a[1...n], we recursively sort a[1...n-1] and then insert A[n] into the sorted array
a[1...n-1]. Write a recurrence for the running time of this recursive version of
 insertion sort.

 answer:
T(n)= {
O(1)            if n = 1 //if the card is empty/one card, its trivially sorted
T(n-1) + O(n)    if n > 1  // if its more than two
}

2.3-5
 Referring back to the searching problem (see Exercise 2.1-3), observe that if the
 sequence A is sorted, we can check the midpoint of the sequence against and
 eliminate half of the sequence from further consideration. The binary search al
gorithm repeats this procedure, halving the size of the remaining portion of the
 sequence each time. Write pseudocode, either iterative or recursive, for binary
 search. Argue that the worst-case running time of binary search is O(lg n)

 answer:
 recursive binary search

arr = array input
start_index
end_index
mid_index
t = target

BINARY_SEARCH(arr,target,start_index,end_index)
    let mid_index = floor ((start_index + end_index) / 2)
    if start_index > end_index 
        ; target not present in the array
        return arr
    else if target = arr[mid_index]
        return arr[mid_index]; found - stop and return the result
    else if  target < arr[mid_index]
        BINARY_SEARCH(arr, target, start_index, mid_index - 1); recurse to the left part
    else
        BINARY_SEARCH(arr, target, mid_index + 1, end_index)
        ; recurse to the right part

on each iteration, we are tracking for start and end index
each time when making recursive call, interval length is half of what it was
after at most lg n steps you find the element or hit an empty inteval

2.3-6
Observe that the while loop of lines 5–7 of the INSERTION-SORT procedure in
 Section 2.1 uses a linear search to scan (backward) through the sorted subarray
 a[1...j-1]. Can we use a binary search (see Exercise 2.3-5) instead to improve
 the overall worst-case running time of insertion sort to O(n lg n)?

 while loop lines 5-7
 while i > 0 and a[i] > key
    a[i+1] = a[1]
    i = i - 1

answer:
insertion sort has 2 part:
1. the part where you need to find the element
2. the part where you need to insert the element in the correct place
even though if we use ibnary search which gives O(lg n),
the second part still needs to check 1 by 1 which gives O(n)
so the total is O(n) + O(lg n) = O(n^2)


 2.3-7
 Describe a O(n lg n)-time algorithm that, given a set S of n integers and another
 integer x, determines whether or not there exist two elements in S whose sum is
 exactly x

 answer:

 ; sort the list
 ; perform binary serach

; list-of-number number -> boolean
nums = sorted list of numbers
let i = 0
let arr.length = nums length
FIND_SUM(nums, x)
    sort nums
    for i = 1 to length(nums)
        complement = x - nums[i]
        if BINARY_SEARCH(nums, complement) is not empty
            return true
        else return false


PROBLEMS
2.1 Insertion sort on small arrays in merge sort

a. 
each sublist has k element -> insetion sort on one list cost roughly O(k^2)
n/k lists

n/k . k^2
k^2 .n /k
= kn -> the total cost if O(nk)

b. 
n/k sorted chunks
merge them all back into one big sorted array
normal merge sort on n items merge about log n levels deep

On x O log n/k = O n log (n/k)

c. cboose k so that nk is at most on the order of n log on
k must not grow faster than log n if k is large

2.2 correctness of bubblesort


BUBBLESORT(a)
for i = 1 to A.length -1 ;outer loop: runs for each element
    for j = A.length downto i + 1 ;inner loop: compares adjacent pairs and swaps if out of order
        if A[j] < A[j-1]
            exchange A[j] with A[j-1]

a. we neeed to prove the following:
1. termination: bubblesort halts and terminates
outer loop: walks through the list one by one until eveyr list is sorted
condition is from 1st index to 1.length-1
each iteration increases i by 1, must stop after n-1 steps

inner loop: for each list from the outer loop, compares pairs and swap the two position
starts from a.length down to i+1
each iteration decrements  j, msut stop after a finite number os teps
base case list is empty -> trivially sorted
there's only 1 item -> return as is

2. correctness for all inputs it always gives the correct result 
the loop terminates because each step inside the inner loop, it checks if one is smaller than another


b. Statepreciselyaloopinvariantfortheforloopinlines2–4,andprovethatthis
 loopinvariantholds.Yourproofshouldusethestructureoftheloopinvariant
 proofpresentedinthischapte

inner loop -> compares adjacent element and swaps if needed
after one full pass, the position of the largest element is shifted to the right
after n pass, the position of the largest leemnt is shifted to n index
this guarantees the largest element is at the end of the array

Loop invariant
At the start of each iteration of the inner lop, the largest element emong A[j...n]
is at position A[n]

Initializastion: After the first iteration completes,
the largest element among all elements gets moved to the end. 

Maintennace: at eveyr iteration cycle, outer loop runs each element
and the inner loop compares and swaps

Termination: at the end of the iteration, return a sorted list

c. 